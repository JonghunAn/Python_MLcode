{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60d15c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W =  [[0.9694098]] W.shape =  (1, 1) b =  [0.79595838] , b.shape =  (1,)\n",
      "Initial error value =  0.08937638481276108 W =  [[0.9694098]] , b =  [0.79595838]\n",
      "step =  0 error value =  0.05508085265690136 W =  [[0.98838214]] , b =  [0.80073629]\n",
      "step =  400 error value =  0.0004002454721567762 W =  [[1.01299152]] , b =  [0.95310797]\n",
      "step =  800 error value =  2.5538027363956348e-05 W =  [[1.00328164]] , b =  [0.98815515]\n",
      "step =  1200 error value =  1.62947712594426e-06 W =  [[1.00082894]] , b =  [0.99700801]\n",
      "step =  1600 error value =  1.0397027405981281e-07 W =  [[1.00020939]] , b =  [0.99924423]\n",
      "step =  2000 error value =  6.633918154448392e-09 W =  [[1.00005289]] , b =  [0.99980909]\n",
      "step =  2400 error value =  4.232831977963389e-10 W =  [[1.00001336]] , b =  [0.99995178]\n",
      "step =  2800 error value =  2.7007970457613017e-11 W =  [[1.00000337]] , b =  [0.99998782]\n",
      "step =  3200 error value =  1.7232681856463813e-12 W =  [[1.00000085]] , b =  [0.99999692]\n",
      "step =  3600 error value =  1.0995469809003831e-13 W =  [[1.00000022]] , b =  [0.99999922]\n",
      "step =  4000 error value =  7.01575978095212e-15 W =  [[1.00000005]] , b =  [0.9999998]\n",
      "step =  4400 error value =  4.476469472336542e-16 W =  [[1.00000001]] , b =  [0.99999995]\n",
      "step =  4800 error value =  2.856251689674997e-17 W =  [[1.]] , b =  [0.99999999]\n",
      "step =  5200 error value =  1.8224578853604547e-18 W =  [[1.]] , b =  [1.]\n",
      "step =  5600 error value =  1.1628338662405138e-19 W =  [[1.]] , b =  [1.]\n",
      "step =  6000 error value =  7.419568571699991e-21 W =  [[1.]] , b =  [1.]\n",
      "step =  6400 error value =  4.734160217369459e-22 W =  [[1.]] , b =  [1.]\n",
      "step =  6800 error value =  3.0209112387203063e-23 W =  [[1.]] , b =  [1.]\n",
      "step =  7200 error value =  1.92957720333948e-24 W =  [[1.]] , b =  [1.]\n",
      "step =  7600 error value =  1.2337472957599061e-25 W =  [[1.]] , b =  [1.]\n",
      "step =  8000 error value =  7.948641367097437e-27 W =  [[1.]] , b =  [1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#x_data = np.array([1,2,3,4,5]).reshape(5,1)\n",
    "#t_data = np.array([2,3,4,5,6]).reshape(5,1)\n",
    "\n",
    "##raw_data에서 input data / target data 분리\n",
    "raw_data = [[1,2],[2,3],[3,4],[4,5],[5,6]]\n",
    "\n",
    "x_data = np.array([i[0] for i in raw_data]).reshape(5,1)\n",
    "t_data = np.array([i[1] for i in raw_data]).reshape(5,1)\n",
    "\n",
    "raw_data = np.array(raw_data)\n",
    "x_data = np.array(raw_data[:,0]).reshape(5,1)\n",
    "t_data = np.array(raw_data[:,1]).reshape(5,1)\n",
    "\n",
    "\n",
    "W = np.random.rand(1,1)\n",
    "b = np.random.rand(1)\n",
    "\n",
    "print(\"W = \",W,\"W.shape = \",W.shape,\"b = \",b,\", b.shape = \",b.shape)\n",
    "\n",
    "def numerical_derivate1(f,x):\n",
    "    delta_x = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x,flags=['multi_index'],op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val)+delta_x\n",
    "        fx1 = f(x)\n",
    "        \n",
    "        x[idx] = float(tmp_val)-delta_x\n",
    "        fx2 = f(x)\n",
    "        grad[idx] = (fx1-fx2)/(2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val\n",
    "        it.iternext()\n",
    "        \n",
    "    return grad\n",
    "\n",
    "def loss_func(x,t):\n",
    "    y = np.dot(x,W)+b\n",
    "    \n",
    "    return (np.sum((t-y)**2)/(len(x)))\n",
    "\n",
    "def error_val(x,t):\n",
    "    y = np.dot(x,W)+b\n",
    "    \n",
    "    return(np.sum((t-y)**2)/(len(x)))\n",
    "\n",
    "def predict(x): \n",
    "    y = np.dot(x,W)+b\n",
    "    \n",
    "    return y\n",
    "\n",
    "\n",
    "\n",
    "learning_rate = 1e-2;\n",
    "\n",
    "f = lambda x : loss_func(x_data,t_data)\n",
    "\n",
    "print(\"Initial error value = \",error_val(x_data,t_data),\"W = \",W,\", b = \",b)\n",
    "\n",
    "for step in range(8001):\n",
    "    W -= learning_rate * numerical_derivate1(f,W)\n",
    "    b -= learning_rate * numerical_derivate1(f,b)\n",
    "    \n",
    "    if(step % 400 ==0):\n",
    "        print(\"step = \",step, \"error value = \",error_val(x_data,t_data),\"W = \",W, \", b = \",b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6f1de40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W =  [[0.11581528]\n",
      " [0.59283215]\n",
      " [0.02337427]\n",
      " [0.1588202 ]] W.shape =  (4, 1) b =  [0.82277664] , b.shape =  (1,)\n",
      "Initial error value =  50.34237432726926 W =  [[0.11581528]\n",
      " [0.59283215]\n",
      " [0.02337427]\n",
      " [0.1588202 ]] , b =  [0.82277664]\n",
      "step =  0 error value =  48.58929534422462\n",
      "step =  1000 error value =  0.03367035956203183\n",
      "step =  2000 error value =  0.004052772101941235\n",
      "step =  3000 error value =  0.00048781664272512\n",
      "step =  4000 error value =  5.8716619374093075e-05\n",
      "step =  5000 error value =  7.067494400072369e-06\n",
      "step =  6000 error value =  8.506872096438085e-07\n",
      "step =  7000 error value =  1.0239395854975276e-07\n",
      "step =  8000 error value =  1.2324768291592057e-08\n",
      "step =  9000 error value =  1.4834851156515287e-09\n",
      "step =  10000 error value =  1.785614168333259e-10\n",
      "step =  11000 error value =  2.1492753281180744e-11\n",
      "step =  12000 error value =  2.587000325830922e-12\n",
      "step =  13000 error value =  3.1138731295305255e-13\n",
      "step =  14000 error value =  3.748049729854079e-14\n",
      "step =  15000 error value =  4.511383794356038e-15\n",
      "step =  16000 error value =  5.430179851614693e-16\n",
      "step =  17000 error value =  6.536099294223628e-17\n",
      "step =  18000 error value =  7.867252726130048e-18\n",
      "step =  19000 error value =  9.46951221307266e-19\n",
      "step =  20000 error value =  1.1398085630655507e-19\n",
      "\n",
      "Elapsed Time => 0:00:02.223775\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "try:\n",
    "    loaded_data = np.loadtxt('./data-01-test-score.csv',delimiter=',',dtype=np.float32)\n",
    "\n",
    "    x_data = loaded_data[:,1:]\n",
    "    t_data = loaded_data[:,[0]]\n",
    "    \n",
    "except FileNotFoundError as err:\n",
    "    print(str(err))\n",
    "except IndexError as err:\n",
    "    print(str(err))\n",
    "except Exception as err:\n",
    "    print(str(err))\n",
    "\n",
    "\n",
    "W = np.random.rand(x_data.shape[-1],1)\n",
    "b = np.random.rand(1)\n",
    "\n",
    "print(\"W = \",W,\"W.shape = \",W.shape,\"b = \",b,\", b.shape = \",b.shape)\n",
    "\n",
    "def numerical_derivate1(f,x):\n",
    "    delta_x = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x,flags=['multi_index'],op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val)+delta_x\n",
    "        fx1 = f(x)\n",
    "        \n",
    "        x[idx] = float(tmp_val)-delta_x\n",
    "        fx2 = f(x)\n",
    "        grad[idx] = (fx1-fx2)/(2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val\n",
    "        it.iternext()\n",
    "        \n",
    "    return grad\n",
    "\n",
    "def loss_func(x,t):\n",
    "    y = np.dot(x,W)+b\n",
    "    \n",
    "    return (np.sum((t-y)**2)/(len(x)))\n",
    "\n",
    "def error_val(x,t):\n",
    "    y = np.dot(x,W)+b\n",
    "    \n",
    "    return(np.sum((t-y)**2)/(len(x)))\n",
    "\n",
    "def predict(x): \n",
    "    y = np.dot(x,W)+b\n",
    "    \n",
    "    return y\n",
    "\n",
    "\n",
    "\n",
    "learning_rate = 1e-3;\n",
    "\n",
    "f = lambda x : loss_func(x_data,t_data)\n",
    "\n",
    "print(\"Initial error value = \",error_val(x_data,t_data),\"W = \",W,\", b = \",b)\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "for step in range(20001):\n",
    "    W -= learning_rate * numerical_derivate1(f,W)\n",
    "    b -= learning_rate * numerical_derivate1(f,b)\n",
    "    \n",
    "    if(step % 1000 ==0):\n",
    "        print(\"step = \",step, \"error value = \",error_val(x_data,t_data))\n",
    "        \n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "print(\"\")\n",
    "print(\"Elapsed Time =>\",end_time-start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
